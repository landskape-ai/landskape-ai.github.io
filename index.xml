<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Landskape AI</title>
    <link>https://landskape.ai/</link>
    <description>Recent content on Landskape AI</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&amp;copy; Landskape AI, 2020 </copyright>
    <lastBuildDate>Sat, 01 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://landskape.ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>APP: Anytime Progressive Pruning</title>
      <link>https://landskape.ai/project/lth/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/project/lth/</guid>
      <description>Ongoing Project
Abstract In this work, we analyze more efficient way of pruning models using progressive rates in an anytime learning regime. We further aim to do conclusive studies on the uniqueness of the sparse models discovered by the algorithm in comparison to conventional pruning.
References: [1] Frankle, Jonathan, and Michael Carbin. &amp;ldquo;The lottery ticket hypothesis: Finding sparse, trainable neural networks.&amp;rdquo; arXiv preprint arXiv:1803.03635 (2018).
[2] Caccia, Lucas, Jing Xu, Myle Ott, Marc&amp;rsquo;Aurelio Ranzato, and Ludovic Denoyer.</description>
    </item>
    
    <item>
      <title>Robustness Survey of Graph Neural Networks</title>
      <link>https://landskape.ai/project/robustness/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/project/robustness/</guid>
      <description>Ongoing project
Abstract In this project, we aim to provide a conclusive thorough overview of robustness of Graph Neural Networks. We also primarily focus on the shortcomings of Stochastic GNNs and work on providing exhaustive empirical results to support our claims and to explore possible solutions to improve robustness in stochastic GNNs.
References [1] Zhang, Ziwei, Chenhao Niu, Peng Cui, Bo Zhang, Wei Cui, and Wenwu Zhu. &amp;ldquo;A Simple and General Graph Neural Network with Stochastic Message Passing.</description>
    </item>
    
    <item>
      <title>What makes an augmentation a good augmentation?</title>
      <link>https://landskape.ai/project/aug/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/project/aug/</guid>
      <description>Ongoing Project
Abstract In this work, we analyze image augmentations under various image quality assessment constraints and try to model a space of all high-performing augmentations used. We further aim to deduce that for an augmentation to perform better than baseline, it needs to fall within this closed bound space, however, we clarify that not all augmentations within this closed bound space qualify to perform better than baseline.</description>
    </item>
    
    <item>
      <title>Rotate to Attend: Convolutional Triplet Attention Module</title>
      <link>https://landskape.ai/publication/triplet/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/publication/triplet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mish: A Self Regularized Non-Monotonic Activation Function</title>
      <link>https://landskape.ai/publication/mish/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/publication/mish/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bharat</title>
      <link>https://landskape.ai/member/bharat/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/bharat/</guid>
      <description>Hi!,I am Bharat ,a third year undergraduate pursuing my B.Tech degree in Department of Electrical Engineering,IIT Delhi.Currently i’m working on Graph Structural Learning for Robust GNN, efficient methods for Neural Architecture search inspired by Human skill learning.My current research interests includes Geometric Deep learning,Optimization Theory,NLP,Computer Vision,Robustness,intersection of GNN with NLP and CV , Federated Learning.</description>
    </item>
    
    <item>
      <title>CCL</title>
      <link>https://landskape.ai/member/ccl/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/ccl/</guid>
      <description>Hi! I&amp;rsquo;m an undergrad at CUHK, dabbling in research at the Multimedia Laboratory (MMLab) and NVIDIA. I&amp;rsquo;m fascinated by CV concepts of generative modelling, multi-modal learning, SSL, as well as ML tasks of generalisation, distributional &amp;amp; adversarial robustness. Apart from aspirations of becoming an academic/researcher, meeting Hugh Laurie and Professor Zisserman are also at the top of my bucket-list!</description>
    </item>
    
    <item>
      <title>Diganta</title>
      <link>https://landskape.ai/member/diganta/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/diganta/</guid>
      <description>$\psi(x) = \tanh(\log(1+{e}^{x}))$
 This equation was the foundational point of my advent in deep learning. I&amp;rsquo;m extremely fascinated and curious of understanding the underlying theoretical mechanisms governing deep learning methods especially in the domain of Mean Field Theory, Non Convex Optimization and Non-Linear Dynamics. I am also inclined towards fundamental research in computer vision especially in the continously evolving sub-domains of Adversarial Robustness, Continual Learning and Self-Supervised Learning.</description>
    </item>
    
    <item>
      <title>Federico</title>
      <link>https://landskape.ai/member/federico/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/federico/</guid>
      <description>Federico was the head of Research at Corvalius. Currently, he serves as the Director of Quantitative Research at Epsilon Acquisition Services. He is a recognized public speaker with 15+ years (in the trenches) delivering on performance-sensitive software on massive and high-frequency data. Working currently on Deep Reinforcement Learning on highly noisy datasets.</description>
    </item>
    
    <item>
      <title>Himanshu</title>
      <link>https://landskape.ai/member/himanshu/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/himanshu/</guid>
      <description>I am a Machine Learning Engineer at Workday. Previously, I was a graduate student in Machine Learning at the Montréal Institute for Learning Algorithms (Mila). Before joining Mila, I worked as a Team Lead at Accenture AI, focusing on Natural Language Processing. I have recently acquired a keen research interest in Computer Vision and Self-Supervised Learning.</description>
    </item>
    
    <item>
      <title>Jaegul</title>
      <link>https://landskape.ai/member/jaegul/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/jaegul/</guid>
      <description>Jaegul is currently an associate professor in the Graduate School of Artificial Intelligence at KAIST. His research area lies in computer vision, natural language processing, and visual analytics. He received M.S in the School of Electrical and Computer Engineering at Georgia Tech in 2009 and Ph.D in the School of Computational Science and Engineering at Georgia Tech in 2013, advised by Prof. Haesun Park. From 2011 to 2014, he has been a research scientist at Georgia Tech.</description>
    </item>
    
    <item>
      <title>Javier</title>
      <link>https://landskape.ai/member/javier/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/javier/</guid>
      <description>During my career I have blended scientific, technical and artistic areas in projects and ventures around the world, from Silicon Valley to the jungles of Bali, and spoken about those ventures and related work at institutions like Stanford University and UC Berkeley, the United Nations FAO HQ, the financial center of London, the International Cultural Diplomacy Conference in Berlin and many others. I consider deep learning a key opportunity to transform our world and make it a better place, looking towards a future in which human beings can have &amp;ldquo;más tiempo para lo más humano&amp;rdquo;, more time for what truly makes us human, for those things we really enjoy.</description>
    </item>
    
    <item>
      <title>Trikay</title>
      <link>https://landskape.ai/member/trikay/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/trikay/</guid>
      <description>I&amp;rsquo;m a senior at the Indian Institute of Technology, Guwahati, majoring in Mathematics and Computing. I&amp;rsquo;m heavily inclined towards the theoretical aspects of deep learning and the math behind the algorithms. I have previously worked in the fields of Data-Driven Discovery of Integral-Differential Equations, Non-Convex Optimization and Attention Mechanisms in Vision. I&amp;rsquo;m currently working on the application of Reinforcement Learning in a medical setting, along with more fundamental research topics such as Activation Functions and Optimization methods.</description>
    </item>
    
    <item>
      <title>About Landskape AI</title>
      <link>https://landskape.ai/about/</link>
      <pubDate>Tue, 12 Jul 2016 15:50:58 +0200</pubDate>
      
      <guid>https://landskape.ai/about/</guid>
      <description>Who we are We are a small team of multi-disciplinary researchers who have a similar goal to explore the facets of theory underlining the abstraction of deep learning. Our team has cumulative experience in graphics, film making, hardware optimization, computer vision, software engineering, astrophysics and extensive knowledge in visualization, optimization and mathematics.
What we do Our goal is to explore the theoretical avenues of deep learning which haven&amp;rsquo;t been extensively discussed and try to connect the dots to have a more firm and concrete understanding of deep learning and the black box associated to it.</description>
    </item>
    
    <item>
      <title>Ajay</title>
      <link>https://landskape.ai/member/ajay/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/member/ajay/</guid>
      <description>Ajay Uppili Arasanipalai is a student at the University of Illinois at Urbana-Champaign. In 2019, He achieved state of the art results on the Stanford DAWNBench competition, where the goal is to reduce the time and cost to train convolutional networks. Currently, Ajay is working with the BH PIRE group on building models for physical parameter extraction from black hole images obtained from general relativity simulations. He is now co-authoring a book on applied natural language processing with transformers that will be published by O’Reilly Media in summer 2021.</description>
    </item>
    
    <item>
      <title>Alex</title>
      <link>https://landskape.ai/member/alex/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/member/alex/</guid>
      <description>Alex recently graduated from MIT with a BS in EECS and will continue his MEng at MIT next year. Last summer, he did an engineering internship at Facebook, where he built an end-to-end ML model as part of the Advertiser Integrity team. He has also done research in robustness and optimization while at MIT. His current research interests include theory for deep learning, robustness/interpretability, continual learning, and the intersection between PL and ML.</description>
    </item>
    
    <item>
      <title>Saurav</title>
      <link>https://landskape.ai/member/sauravm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/member/sauravm/</guid>
      <description>Hi! I&amp;rsquo;m an incoming an incoming freshman at the University of Edinburgh. I’m currently learning about Self-Supervised Representation Learning, Graphical Models and exploring the theoretical foundations of deep learning.</description>
    </item>
    
  </channel>
</rss>
