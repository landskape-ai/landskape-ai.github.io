<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Landskape AI</title>
    <link>https://landskape.ai/</link>
    <description>Recent content on Landskape AI</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&amp;copy; Landskape AI, 2020 </copyright>
    <lastBuildDate>Mon, 04 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://landskape.ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>APP: Anytime Progressive Pruning</title>
      <link>https://landskape.ai/publication/app/</link>
      <pubDate>Mon, 04 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/publication/app/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AP/GP: Anytime Progressive Growing &#43; Pruning</title>
      <link>https://landskape.ai/project/apgp/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/project/apgp/</guid>
      <description>Ongoing Project
Abstract In this work, we propose effective and efficient solutions in regards to the issues presented in Misra et al. (2022) &amp;ldquo;APP: Anytime Progressive Pruning&amp;rdquo;. Precisely, we propose a new algorithm &amp;ldquo;Anytime Progressive Pruning + Growing&amp;rdquo; (AP/GP) that solves the issue of APP with no replay and high target sparsity while inducing similar regularization effect as that of APP. The proposed algorithm takes advantage of progressive growing and pruning techniques to achieve the same effective target sparsity as that of APP while not requiring the prior knowledge of the total number of megabatches in the stream.</description>
    </item>
    
    <item>
      <title>PSNR: Progressive Scale Noisy Reconstruction</title>
      <link>https://landskape.ai/project/psnr/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/project/psnr/</guid>
      <description>Ongoing Project
Abstract In this work, we propose the first progressive denoising framework inspired from the ALMA framework. In addition, we propose a new metric for evaluating the anytime performance of reconstruction models in the ALMA framework. Furthermore, we analyse and investigate the different effects of changing the scale of progressive noise and the size of the megabatches with respect to the final and the anytime performance.
References: [1] Misra, Diganta, Bharat Runwal, Tianlong Chen, Zhangyang Wang, and Irina Rish.</description>
    </item>
    
    <item>
      <title>Reprogrammers are robust learners</title>
      <link>https://landskape.ai/project/reprogramming/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/project/reprogramming/</guid>
      <description>Ongoing Project
Abstract In this work, we investigate the effect of adversarial reprogramming on the robustness of the model upon transfer. We further are interested in adding a robustness objective into the constrained optimization process of reprogramming. We further demonstrate the effect of scaling on reprogramming and do an in-depth cost analysis breakdown comparison of reprogramming and fine-tuning.
References: [1] Elsayed, Gamaleldin F., Ian Goodfellow, and Jascha Sohl-Dickstein. &amp;ldquo;Adversarial reprogramming of neural networks.</description>
    </item>
    
    <item>
      <title>Rotate to Attend: Convolutional Triplet Attention Module</title>
      <link>https://landskape.ai/publication/triplet/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/publication/triplet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mish: A Self Regularized Non-Monotonic Activation Function</title>
      <link>https://landskape.ai/publication/mish/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/publication/mish/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bharat</title>
      <link>https://landskape.ai/member/bharat/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/bharat/</guid>
      <description>Hi!,I am Bharat ,a third year undergraduate pursuing my B.Tech degree in Department of Electrical Engineering,IIT Delhi.Currently i’m working on Graph Structural Learning for Robust GNN, efficient methods for Neural Architecture search inspired by Human skill learning.My current research interests includes Geometric Deep learning,Optimization Theory,NLP,Computer Vision,Robustness,intersection of GNN with NLP and CV , Federated Learning.</description>
    </item>
    
    <item>
      <title>Diganta</title>
      <link>https://landskape.ai/member/diganta/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/diganta/</guid>
      <description>$\psi(x) = \tanh(\log(1+{e}^{x}))$
 This equation was the foundational point of my advent in deep learning. I&amp;rsquo;m extremely fascinated and curious of understanding the underlying theoretical mechanisms governing deep learning methods especially in the domain of Mean Field Theory, Non Convex Optimization and Non-Linear Dynamics. I am also inclined towards fundamental research in computer vision especially in the continously evolving sub-domains of Adversarial Robustness, Continual Learning and Self-Supervised Learning.</description>
    </item>
    
    <item>
      <title>Federico</title>
      <link>https://landskape.ai/member/federico/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/federico/</guid>
      <description>Federico was the head of Research at Corvalius. Currently, he serves as the Director of Quantitative Research at Epsilon Acquisition Services. He is a recognized public speaker with 15+ years (in the trenches) delivering on performance-sensitive software on massive and high-frequency data. Working currently on Deep Reinforcement Learning on highly noisy datasets.</description>
    </item>
    
    <item>
      <title>Himanshu</title>
      <link>https://landskape.ai/member/himanshu/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/himanshu/</guid>
      <description>I am a Machine Learning Engineer at Workday. Previously, I was a graduate student in Machine Learning at the Montréal Institute for Learning Algorithms (Mila). Before joining Mila, I worked as a Team Lead at Accenture AI, focusing on Natural Language Processing. I have recently acquired a keen research interest in Computer Vision and Self-Supervised Learning.</description>
    </item>
    
    <item>
      <title>Javier</title>
      <link>https://landskape.ai/member/javier/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/javier/</guid>
      <description>During my career I have blended scientific, technical and artistic areas in projects and ventures around the world, from Silicon Valley to the jungles of Bali, and spoken about those ventures and related work at institutions like Stanford University and UC Berkeley, the United Nations FAO HQ, the financial center of London, the International Cultural Diplomacy Conference in Berlin and many others. I consider deep learning a key opportunity to transform our world and make it a better place, looking towards a future in which human beings can have &amp;ldquo;más tiempo para lo más humano&amp;rdquo;, more time for what truly makes us human, for those things we really enjoy.</description>
    </item>
    
    <item>
      <title>Richeek</title>
      <link>https://landskape.ai/member/richeek/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/richeek/</guid>
      <description>I am currently majoring in Computer Science and Engineering from the Indian Institute of Technology Bombay. My research interests are somewhat in the intersection of Image Processing, Compressed Sensing, Theoretical Deep Learning and Causal Statistics. Recently, I have been enjoying reading about the interesting design decisions in Graph Neural Networks! I am always on the lookout for exciting research, so do drop by if you want to have a discussion!</description>
    </item>
    
    <item>
      <title>Trikay</title>
      <link>https://landskape.ai/member/trikay/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      
      <guid>https://landskape.ai/member/trikay/</guid>
      <description>I&amp;rsquo;m a senior at the Indian Institute of Technology, Guwahati, majoring in Mathematics and Computing. I&amp;rsquo;m heavily inclined towards the theoretical aspects of deep learning and the math behind the algorithms. I have previously worked in the fields of Data-Driven Discovery of Integral-Differential Equations, Non-Convex Optimization and Attention Mechanisms in Vision. I&amp;rsquo;m currently working on the application of Reinforcement Learning in a medical setting, along with more fundamental research topics such as Activation Functions and Optimization methods.</description>
    </item>
    
    <item>
      <title>About Landskape AI</title>
      <link>https://landskape.ai/about/</link>
      <pubDate>Tue, 12 Jul 2016 15:50:58 +0200</pubDate>
      
      <guid>https://landskape.ai/about/</guid>
      <description>Who we are We are a small team of multi-disciplinary researchers who have a similar goal to explore the facets of theory underlining the abstraction of deep learning. Our team has cumulative experience in graphics, film making, hardware optimization, computer vision, software engineering, astrophysics and extensive knowledge in visualization, optimization and mathematics.
What we do Our goal is to explore the theoretical avenues of deep learning which haven&amp;rsquo;t been extensively discussed and try to connect the dots to have a more firm and concrete understanding of deep learning and the black box associated to it.</description>
    </item>
    
    <item>
      <title>Ajay</title>
      <link>https://landskape.ai/member/ajay/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/member/ajay/</guid>
      <description>Ajay Uppili Arasanipalai is a student at the University of Illinois at Urbana-Champaign. In 2019, He achieved state of the art results on the Stanford DAWNBench competition, where the goal is to reduce the time and cost to train convolutional networks. Currently, Ajay is working with the BH PIRE group on building models for physical parameter extraction from black hole images obtained from general relativity simulations. He is now co-authoring a book on applied natural language processing with transformers that will be published by O’Reilly Media in summer 2021.</description>
    </item>
    
  </channel>
</rss>
