<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Landskape AI</title>
    <link>https://landskape.ai/project/</link>
    <description>Recent content in Projects on Landskape AI</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&amp;copy; Landskape AI, 2020 </copyright>
    <lastBuildDate>Sat, 01 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://landskape.ai/project/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>APP: Anytime Progressive Pruning</title>
      <link>https://landskape.ai/project/lth/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/project/lth/</guid>
      <description>Ongoing Project
Abstract In this work, we analyze more efficient way of pruning models using progressive rates in an anytime learning regime. We further aim to do conclusive studies on the uniqueness of the sparse models discovered by the algorithm in comparison to conventional pruning.
References: [1] Frankle, Jonathan, and Michael Carbin. &amp;ldquo;The lottery ticket hypothesis: Finding sparse, trainable neural networks.&amp;rdquo; arXiv preprint arXiv:1803.03635 (2018).
[2] Caccia, Lucas, Jing Xu, Myle Ott, Marc&amp;rsquo;Aurelio Ranzato, and Ludovic Denoyer.</description>
    </item>
    
    <item>
      <title>Robustness Survey of Graph Neural Networks</title>
      <link>https://landskape.ai/project/robustness/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/project/robustness/</guid>
      <description>Ongoing project
Abstract In this project, we aim to provide a conclusive thorough overview of robustness of Graph Neural Networks. We also primarily focus on the shortcomings of Stochastic GNNs and work on providing exhaustive empirical results to support our claims and to explore possible solutions to improve robustness in stochastic GNNs.
References [1] Zhang, Ziwei, Chenhao Niu, Peng Cui, Bo Zhang, Wei Cui, and Wenwu Zhu. &amp;ldquo;A Simple and General Graph Neural Network with Stochastic Message Passing.</description>
    </item>
    
    <item>
      <title>What makes an augmentation a good augmentation?</title>
      <link>https://landskape.ai/project/aug/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://landskape.ai/project/aug/</guid>
      <description>Ongoing Project
Abstract In this work, we analyze image augmentations under various image quality assessment constraints and try to model a space of all high-performing augmentations used. We further aim to deduce that for an augmentation to perform better than baseline, it needs to fall within this closed bound space, however, we clarify that not all augmentations within this closed bound space qualify to perform better than baseline.</description>
    </item>
    
  </channel>
</rss>
